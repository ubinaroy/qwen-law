[2025-03-11 23:34:19,506] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)

Data Mapping...

Map:   0%|          | 0/500 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 14777.31 examples/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.05s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:01<00:01,  1.04it/s]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:02<00:00,  1.10it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.16it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.12it/s]
/root/miniconda3/envs/qwen_law/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:355: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
[1m[34mswanlab[0m[0m: \ Waiting for the swanlab cloud response.                                                                                                    [1m[34mswanlab[0m[0m: \ Getting project...                                                                                                    [1m[34mswanlab[0m[0m: \ Creating experiment...                                                                                                    /data/workbench/dpo_train.py:118: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `DPOTrainer.__init__`. Use `processing_class` instead.
  dpo_trainer = DPOTrainer(
[1m[34mswanlab[0m[0m: Tracking run with swanlab version 0.4.12
[1m[34mswanlab[0m[0m: Run data will be saved locally in [35m[1m/data/workbench/swanlog/run-20250311_233442-60062a55[0m[0m
[1m[34mswanlab[0m[0m: ðŸ‘‹ Hi [1m[39mroychen37326[0m[0m, welcome to swanlab!
[1m[34mswanlab[0m[0m: Syncing run [33mQwen-dpo[0m to the cloud
[1m[34mswanlab[0m[0m: ðŸŒŸ Run `[1mswanlab watch /data/workbench/swanlog[0m` to view SwanLab Experiment Dashboard locally
[1m[34mswanlab[0m[0m: ðŸ  View project at [34m[4mhttps://swanlab.cn/@roychen37326/Qwen-Law[0m[0m
[1m[34mswanlab[0m[0m: ðŸš€ View run at [34m[4mhttps://swanlab.cn/@roychen37326/Qwen-Law/runs/374sc8cofkryujydsvv06[0m[0m
Extracting prompt in train dataset:   0%|          | 0/500 [00:00<?, ? examples/s]Extracting prompt in train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 10869.51 examples/s]
Applying chat template to train dataset:   0%|          | 0/500 [00:00<?, ? examples/s]Applying chat template to train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 13021.10 examples/s]
Tokenizing train dataset:   0%|          | 0/500 [00:00<?, ? examples/s]Tokenizing train dataset:  21%|â–ˆâ–ˆ        | 103/500 [00:00<00:00, 1009.30 examples/s]Tokenizing train dataset:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 216/500 [00:00<00:00, 1072.97 examples/s]Tokenizing train dataset:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 371/500 [00:00<00:00, 1046.78 examples/s]Tokenizing train dataset:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 481/500 [00:00<00:00, 1062.54 examples/s]Tokenizing train dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 1057.43 examples/s]
Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.

DPO training...

  0%|          | 0/93 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/root/miniconda3/envs/qwen_law/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
  1%|          | 1/93 [00:07<11:35,  7.56s/it]  2%|â–         | 2/93 [00:13<10:02,  6.62s/it]  3%|â–Ž         | 3/93 [00:19<09:36,  6.40s/it]  4%|â–         | 4/93 [00:25<09:20,  6.29s/it]  5%|â–Œ         | 5/93 [00:31<09:07,  6.22s/it]  6%|â–‹         | 6/93 [00:37<08:43,  6.02s/it]  8%|â–Š         | 7/93 [00:43<08:29,  5.92s/it]  9%|â–Š         | 8/93 [00:48<08:11,  5.78s/it] 10%|â–‰         | 9/93 [00:54<08:10,  5.84s/it] 11%|â–ˆ         | 10/93 [01:01<08:23,  6.06s/it]                                                11%|â–ˆ         | 10/93 [01:01<08:23,  6.06s/it] 12%|â–ˆâ–        | 11/93 [01:07<08:16,  6.05s/it] 13%|â–ˆâ–Ž        | 12/93 [01:13<08:10,  6.05s/it] 14%|â–ˆâ–        | 13/93 [01:18<07:44,  5.80s/it] 15%|â–ˆâ–Œ        | 14/93 [01:24<07:51,  5.97s/it] 16%|â–ˆâ–Œ        | 15/93 [01:30<07:41,  5.92s/it] 17%|â–ˆâ–‹        | 16/93 [01:37<07:48,  6.09s/it] 18%|â–ˆâ–Š        | 17/93 [01:43<07:43,  6.10s/it] 19%|â–ˆâ–‰        | 18/93 [01:49<07:33,  6.04s/it] 20%|â–ˆâ–ˆ        | 19/93 [01:54<07:06,  5.77s/it] 22%|â–ˆâ–ˆâ–       | 20/93 [01:59<06:55,  5.69s/it]                                                22%|â–ˆâ–ˆâ–       | 20/93 [01:59<06:55,  5.69s/it] 23%|â–ˆâ–ˆâ–Ž       | 21/93 [02:06<07:01,  5.86s/it] 24%|â–ˆâ–ˆâ–Ž       | 22/93 [02:12<07:04,  5.98s/it] 25%|â–ˆâ–ˆâ–       | 23/93 [02:18<06:51,  5.88s/it] 26%|â–ˆâ–ˆâ–Œ       | 24/93 [02:24<06:50,  5.95s/it] 27%|â–ˆâ–ˆâ–‹       | 25/93 [02:29<06:40,  5.88s/it] 28%|â–ˆâ–ˆâ–Š       | 26/93 [02:35<06:32,  5.86s/it] 29%|â–ˆâ–ˆâ–‰       | 27/93 [02:41<06:28,  5.89s/it] 30%|â–ˆâ–ˆâ–ˆ       | 28/93 [02:47<06:24,  5.91s/it] 31%|â–ˆâ–ˆâ–ˆ       | 29/93 [02:54<06:31,  6.11s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 30/93 [02:59<06:16,  5.98s/it]                                                32%|â–ˆâ–ˆâ–ˆâ–      | 30/93 [02:59<06:16,  5.98s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 31/93 [03:06<06:29,  6.28s/it]/root/miniconda3/envs/qwen_law/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 34%|â–ˆâ–ˆâ–ˆâ–      | 32/93 [03:14<06:44,  6.64s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 33/93 [03:20<06:28,  6.47s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 34/93 [03:26<06:15,  6.36s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 35/93 [03:32<06:11,  6.40s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 36/93 [03:38<05:53,  6.19s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 37/93 [03:44<05:35,  5.99s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 38/93 [03:50<05:40,  6.20s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 39/93 [03:56<05:31,  6.13s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 40/93 [04:03<05:35,  6.33s/it]                                                43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 40/93 [04:03<05:35,  6.33s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 41/93 [04:09<05:23,  6.21s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 42/93 [04:15<05:10,  6.09s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 43/93 [04:20<04:54,  5.89s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 44/93 [04:27<04:59,  6.11s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 45/93 [04:33<04:49,  6.02s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 46/93 [04:38<04:37,  5.91s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 47/93 [04:45<04:41,  6.12s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 48/93 [04:51<04:35,  6.13s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 49/93 [04:57<04:19,  5.90s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/93 [05:03<04:15,  5.95s/it]                                                54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 50/93 [05:03<04:15,  5.95s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 51/93 [05:09<04:10,  5.95s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 52/93 [05:14<03:57,  5.79s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 53/93 [05:19<03:44,  5.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 54/93 [05:26<03:50,  5.92s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 55/93 [05:32<03:53,  6.14s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 56/93 [05:39<03:51,  6.25s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 57/93 [05:45<03:38,  6.08s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 58/93 [05:50<03:29,  6.00s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 59/93 [05:57<03:25,  6.04s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 60/93 [06:02<03:14,  5.90s/it]                                                65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 60/93 [06:02<03:14,  5.90s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 61/93 [06:09<03:16,  6.14s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 62/93 [06:15<03:08,  6.08s/it]/root/miniconda3/envs/qwen_law/lib/python3.10/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 63/93 [06:23<03:17,  6.58s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 64/93 [06:28<03:02,  6.31s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 65/93 [06:34<02:48,  6.03s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 66/93 [06:39<02:40,  5.93s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 67/93 [06:45<02:34,  5.95s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 68/93 [06:51<02:28,  5.95s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 69/93 [06:58<02:25,  6.07s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 70/93 [07:03<02:15,  5.90s/it]                                                75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 70/93 [07:03<02:15,  5.90s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 71/93 [07:09<02:10,  5.94s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 72/93 [07:16<02:11,  6.24s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 73/93 [07:22<02:02,  6.14s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 74/93 [07:28<01:54,  6.03s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 75/93 [07:34<01:51,  6.20s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 76/93 [07:40<01:43,  6.11s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 77/93 [07:47<01:42,  6.43s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 78/93 [07:53<01:31,  6.08s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 79/93 [07:59<01:26,  6.17s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 80/93 [08:04<01:16,  5.88s/it]                                                86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 80/93 [08:04<01:16,  5.88s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 81/93 [08:10<01:09,  5.81s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 82/93 [08:16<01:05,  5.93s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 83/93 [08:23<01:01,  6.19s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 84/93 [08:29<00:55,  6.11s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 85/93 [08:35<00:48,  6.10s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 86/93 [08:41<00:43,  6.19s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 87/93 [08:47<00:36,  6.13s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 88/93 [08:53<00:30,  6.07s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 89/93 [08:59<00:24,  6.08s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 90/93 [09:05<00:17,  5.95s/it]                                                97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 90/93 [09:05<00:17,  5.95s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 91/93 [09:11<00:11,  5.90s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 92/93 [09:16<00:05,  5.80s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 93/93 [09:22<00:00,  5.86s/it]                                               100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 93/93 [09:26<00:00,  5.86s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 93/93 [09:26<00:00,  6.10s/it]
{'loss': 2.7816, 'grad_norm': 5.41475772857666, 'learning_rate': 5e-07, 'rewards/chosen': -0.005286195315420628, 'rewards/rejected': -0.0018342214170843363, 'rewards/accuracies': 0.3499999940395355, 'rewards/margins': -0.0034519736655056477, 'logps/chosen': -162.23007202148438, 'logps/rejected': -224.8182830810547, 'logits/chosen': -0.21786808967590332, 'logits/rejected': -0.37274056673049927, 'epoch': 0.32}
{'loss': 2.7593, 'grad_norm': 5.032658576965332, 'learning_rate': 4.823045180793913e-07, 'rewards/chosen': -0.012328991666436195, 'rewards/rejected': -0.020294640213251114, 'rewards/accuracies': 0.5562499761581421, 'rewards/margins': 0.007965647615492344, 'logps/chosen': -157.30519104003906, 'logps/rejected': -213.57034301757812, 'logits/chosen': -0.2508629560470581, 'logits/rejected': -0.38368305563926697, 'epoch': 0.64}
{'loss': 2.7345, 'grad_norm': 6.318203926086426, 'learning_rate': 4.317231129607859e-07, 'rewards/chosen': 0.002489900914952159, 'rewards/rejected': -0.018013013526797295, 'rewards/accuracies': 0.581250011920929, 'rewards/margins': 0.020502915605902672, 'logps/chosen': -167.51795959472656, 'logps/rejected': -220.3493194580078, 'logits/chosen': -0.1691226065158844, 'logits/rejected': -0.3768903613090515, 'epoch': 0.96}
{'loss': 2.6926, 'grad_norm': 4.9503302574157715, 'learning_rate': 3.55416283362546e-07, 'rewards/chosen': 0.012671887874603271, 'rewards/rejected': -0.02931051328778267, 'rewards/accuracies': 0.731249988079071, 'rewards/margins': 0.04198240116238594, 'logps/chosen': -170.88571166992188, 'logps/rejected': -221.1697998046875, 'logits/chosen': -0.20761163532733917, 'logits/rejected': -0.42590054869651794, 'epoch': 1.28}
{'loss': 2.6596, 'grad_norm': 4.798973083496094, 'learning_rate': 2.641863182732685e-07, 'rewards/chosen': 0.01031920313835144, 'rewards/rejected': -0.0483996607363224, 'rewards/accuracies': 0.768750011920929, 'rewards/margins': 0.05871886759996414, 'logps/chosen': -160.5677032470703, 'logps/rejected': -218.1814422607422, 'logits/chosen': -0.211133673787117, 'logits/rejected': -0.36588239669799805, 'epoch': 1.6}
{'loss': 2.6397, 'grad_norm': 5.619994163513184, 'learning_rate': 1.70948083275794e-07, 'rewards/chosen': 0.024062076583504677, 'rewards/rejected': -0.04494132474064827, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 0.0690034031867981, 'logps/chosen': -157.0780029296875, 'logps/rejected': -213.25375366210938, 'logits/chosen': -0.2517285645008087, 'logits/rejected': -0.37141919136047363, 'epoch': 1.92}
{'loss': 2.6392, 'grad_norm': 6.067662715911865, 'learning_rate': 8.890074238378073e-08, 'rewards/chosen': 0.011559988372027874, 'rewards/rejected': -0.05794905498623848, 'rewards/accuracies': 0.8125, 'rewards/margins': 0.06950904428958893, 'logps/chosen': -166.77195739746094, 'logps/rejected': -219.8907470703125, 'logits/chosen': -0.24289731681346893, 'logits/rejected': -0.4413941502571106, 'epoch': 2.24}
{'loss': 2.6084, 'grad_norm': 5.527740001678467, 'learning_rate': 2.965923349633778e-08, 'rewards/chosen': 0.028835484758019447, 'rewards/rejected': -0.056862104684114456, 'rewards/accuracies': 0.8687499761581421, 'rewards/margins': 0.08569759130477905, 'logps/chosen': -161.1888427734375, 'logps/rejected': -208.88119506835938, 'logits/chosen': -0.21700027585029602, 'logits/rejected': -0.3511756658554077, 'epoch': 2.56}
{'loss': 2.6271, 'grad_norm': 5.738589763641357, 'learning_rate': 1.61001300920377e-09, 'rewards/chosen': 0.019081342965364456, 'rewards/rejected': -0.056656062602996826, 'rewards/accuracies': 0.8812500238418579, 'rewards/margins': 0.07573740184307098, 'logps/chosen': -165.5309600830078, 'logps/rejected': -228.86831665039062, 'logits/chosen': -0.18565498292446136, 'logits/rejected': -0.3785063922405243, 'epoch': 2.88}
{'train_runtime': 567.0701, 'train_samples_per_second': 2.645, 'train_steps_per_second': 0.164, 'train_loss': 2.6809710430842575, 'epoch': 2.98}
[1m[34mswanlab[0m[0m: ðŸŒŸ Run `[1mswanlab watch /data/workbench/swanlog[0m` to view SwanLab Experiment Dashboard locally
[1m[34mswanlab[0m[0m: ðŸ  View project at [34m[4mhttps://swanlab.cn/@roychen37326/Qwen-Law[0m[0m
[1m[34mswanlab[0m[0m: ðŸš€ View run at [34m[4mhttps://swanlab.cn/@roychen37326/Qwen-Law/runs/374sc8cofkryujydsvv06[0m[0m
[1m[34mswanlab[0m[0m: \ Waiting for uploading complete[1m[34mswanlab[0m[0m: | Waiting for uploading complete[1m[34mswanlab[0m[0m: / Waiting for uploading complete[1m[34mswanlab[0m[0m: - Waiting for uploading complete[1m[34mswanlab[0m[0m: \ Waiting for uploading complete[1m[34mswanlab[0m[0m: | Waiting for uploading complete[1m[34mswanlab[0m[0m: / Waiting for uploading complete[1m[34mswanlab[0m[0m: - Waiting for uploading complete                                                                                                    [1m[34mswanlab[0m[0m: \ Updating experiment status...                                                                                                    
Finished...

